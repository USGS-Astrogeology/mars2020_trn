{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "\n",
    "# Environment.yml for deploy\n",
    "# Create tiffs from cubes and clip to overlap using the warp/translate\n",
    "# Plot axes/label axes\n",
    "# Function documentation\n",
    "# Bin script tiff creation\n",
    "# Analysis bin script\n",
    "    # - Quiver png\n",
    "    # - Homography.txt (9 numbers)\n",
    "    # - Dataframe to csv (keep names the same)\n",
    "    # - Stats to csv (Dataframe describe data + quantile data(x, y, magnitude))\n",
    "\n",
    "# Box to Histogram\n",
    "# Correlation/Coregistration in Z dimension\n",
    "    # - Apply homography\n",
    "    # - Difference the two DTMs for some Z offset\n",
    "\n",
    "#-------Nice To Have-------\n",
    "# Specify meters or pixels for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import gdal\n",
    "import affine\n",
    "from osgeo import ogr\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from plio.geofuncs import geofuncs\n",
    "from plio.io.io_gdal import GeoDataset\n",
    "from autocnet.matcher import subpixel as sp\n",
    "from autocnet.transformation import homography as hg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'plasma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the paths to cubes and tiffs\n",
    "hirise_cub1 = \"ESP_023524_1985_1m_o_isis3.cub\"\n",
    "hirise_cub2 = \"ESP_048908_1985_1m_o_isis3.cub\"\n",
    "ctx_cub1 = \"F05_037607_2008_XN_20N282W_v6_PosAndVelAndAngles_20m_o.cub\"\n",
    "ctx_cub2 = \"J03_045994_1986_XN_18N282W_v6_20m_o.cub\"\n",
    "ctx_cub3 = \"F05_037607_2008_XN_20N282W_v6_PosAndVelAndAngles_6m_o.cub\"\n",
    "ctx_cub4 = \"J03_045994_1986_XN_18N282W_v6_6m_o.cub\"\n",
    "hrsc_cub = \"H5270_0000_ND4.IMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJCS[\"Equirectangular Mars\",\n",
      "    GEOGCS[\"GCS_Mars\",\n",
      "        DATUM[\"D_Mars\",\n",
      "            SPHEROID[\"Mars_localRadius\",3396190,0]],\n",
      "        PRIMEM[\"Reference_Meridian\",0],\n",
      "        UNIT[\"degree\",0.0174532925199433]],\n",
      "    PROJECTION[\"Equirectangular\"],\n",
      "    PARAMETER[\"latitude_of_origin\",0],\n",
      "    PARAMETER[\"central_meridian\",0],\n",
      "    PARAMETER[\"standard_parallel_1\",18.6],\n",
      "    PARAMETER[\"false_easting\",0],\n",
      "    PARAMETER[\"false_northing\",0]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# basepath = '/Volumes/Blueman/HiRISE_Jezero/'\n",
    "# basepath = '/Volumes/Blueman/CTX_Jezero/20m_ctx/'\n",
    "basepath = '/Volumes/Blueman/CTX_Jezero/6m_ctx/'\n",
    "# basepath = '/Volumes/Blueman/HRSC_Jezero/'\n",
    "\n",
    "cub_image1 = os.path.join(basepath, ctx_cub3)\n",
    "cub_image2 = os.path.join('/Volumes/Blueman/HRSC_Jezero/', hrsc_cub)\n",
    "\n",
    "tiff_image1 = os.path.splitext(cub_image1)[0] + '.tiff'\n",
    "tiff_image2 = os.path.splitext(cub_image2)[0] + '.tiff'\n",
    "\n",
    "i = gdal.Info(cub_image1, format='json')\n",
    "print(i['coordinateSystem']['wkt'])\n",
    "print('Equirectangular' in i['coordinateSystem']['wkt'])\n",
    "\n",
    "resample = 'bilinear'\n",
    "res = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all geo data for the two co-registered tiffs\n",
    "cub_geo1 = GeoDataset(cub_image1)\n",
    "cub_geo2 = GeoDataset(cub_image2)\n",
    "overlap = cub_geo1.compute_overlap(cub_geo2)[0]\n",
    "\n",
    "overlap_points1 = [cub_geo1.latlon_to_pixel(i[1], i[0]) for i in overlap][::2]\n",
    "overlap_points2 = [cub_geo2.latlon_to_pixel(i[1], i[0]) for i in overlap][::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "5760 9730\n"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists(tiff_image_mod1):\n",
    "ul, lr = overlap_points1\n",
    "\n",
    "minx1, miny1= ul\n",
    "maxx1, maxy1 = lr\n",
    "\n",
    "fp = gdal.Translate(tiff_image1, cub_image1, srcWin=[minx1, miny1, maxx1 - minx1, maxy1 - miny1])\n",
    "del(fp)\n",
    "\n",
    "fp = gdal.Warp(tiff_image1, tiff_image1, \n",
    "               targetAlignedPixels=True, \n",
    "               xRes = res, yRes = res, \n",
    "               resampleAlg=resample)\n",
    "del(fp)\n",
    "# outputBounds = (minx1, miny1, maxx1, maxy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(tiff_image_mod2):\n",
    "ul, lr = overlap_points2\n",
    "\n",
    "minx2, miny2= ul\n",
    "maxx2, maxy2 = lr\n",
    "\n",
    "fp = gdal.Translate(tiff_image2, cub_image2, srcWin=[minx2, miny2, maxx2 - minx2, maxy2 - miny2])\n",
    "del(fp)\n",
    "\n",
    "fp = gdal.Warp(tiff_image2, tiff_image2, \n",
    "               targetAlignedPixels=True, \n",
    "               xRes = res, yRes = res, \n",
    "               resampleAlg=resample)\n",
    "del(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the images and there overlapping grid area\n",
    "def show_initial_coregistration(source_image, destination_image):\n",
    "    plt.figure(0, figsize=(10, 10))\n",
    "    plt.imshow(source_image, alpha=.5, cmap='Greys')\n",
    "    plt.imshow(destination_image, alpha=.5, cmap='Greys')\n",
    "    plt.show()\n",
    "\n",
    "# Show the quiver plot of the offsets\n",
    "def display_quiver(comp_df, source_image, mask = [], scale = 100, scale_units = 'inches', **kwargs):\n",
    "    if len(mask) != 0:\n",
    "        comp_df = comp_df[mask]\n",
    "    \n",
    "    plt.figure(4, figsize=(20, 20))\n",
    "    plt.imshow(source_image, cmap=\"Greys\")\n",
    "    plt.quiver(comp_df['destination_x'], comp_df['destination_y'], \n",
    "               -(comp_df['xoff']), (comp_df['yoff']),\n",
    "               color = 'Red', scale = scale, scale_units = scale_units, **kwargs)\n",
    "    plt.show()\n",
    "    \n",
    "# Given an index in the dataframe examine the before and after\n",
    "# when the offset is applied\n",
    "def examine_point(idx, size, comp_df, source_image, destination_image, mask = []):\n",
    "    if len(mask) != 0:\n",
    "        comp_df = comp_df[mask]\n",
    "        \n",
    "    plt.figure(2, figsize=(5, 5))\n",
    "    plt.text(20, 50, 'Before Offset Correction', fontsize=12)\n",
    "    x, y = int(comp_df.iloc[idx]['source_x']), int(comp_df.iloc[idx]['source_y'])\n",
    "    plt.imshow(source_image[y - size:y + size, x - size:x + size], alpha = .5, cmap='Greys')\n",
    "\n",
    "    x, y = int(comp_df.iloc[idx]['destination_x']), int(comp_df.iloc[idx]['destination_y'])\n",
    "    plt.imshow(destination_image[y - size:y + size, x - size:x + size], alpha = .5, cmap='Greys')\n",
    "\n",
    "    plt.figure(3, figsize=(5, 5))\n",
    "    plt.text(20, 50, 'After Offset Correction', fontsize=12)\n",
    "    x, y = int(comp_df.iloc[idx]['offset_source_x']), int(comp_df.iloc[idx]['offset_source_y'])\n",
    "    plt.imshow(source_image[y - size: y + size, x - size: x + size], alpha = .5, cmap='Greys')\n",
    "\n",
    "    x, y = int(comp_df.iloc[idx]['destination_x']), int(comp_df.iloc[idx]['destination_y'])\n",
    "    plt.imshow(destination_image[y - size:y + size, x - size:x + size], alpha = .5, cmap='Greys')\n",
    "    plt.show()\n",
    "    \n",
    "    offset_x, offset_y, corr = comp_df.iloc[idx][['xoff', 'yoff', 'corr']]\n",
    "    print('X Offset: {}\\nY Offset: {}\\nCorrelation: {}'.format(offset_x, offset_y, corr))\n",
    "    \n",
    "def compute_homography(comp_df):\n",
    "    x1 = np.array([*zip(comp_df['offset_source_x'].__array__(), comp_df['offset_source_y'].__array__())])\n",
    "    x2 = np.array([*zip(comp_df['destination_x'].__array__(), comp_df['destination_y'].__array__())])\n",
    "    H, mask = hg.compute_homography(x1, x2)\n",
    "    \n",
    "    return H, mask\n",
    "\n",
    "# Apply the homography to the source image and display\n",
    "def apply_homography(comp_df, source_image, destination_image):\n",
    "    H, mask = compute_homography(comp_df)\n",
    "\n",
    "    w, h = source_image.shape\n",
    "    result = cv2.warpPerspective(source_image, H, (h, w))\n",
    "    result[result == 0] = np.NAN\n",
    "\n",
    "    plt.figure(0, figsize=(10, 10))\n",
    "    plt.imshow(result, cmap='Greys', alpha = .5)\n",
    "    plt.imshow(destination_image, cmap='Greys', alpha = .5)\n",
    "    \n",
    "def generate_point_grid(source_geo, destination_geo, source_raster, destination_raster, size):\n",
    "    # Compute the overlap and get the corners now that\n",
    "    # we have the geometry\n",
    "    overlap_hull = source_geo.compute_overlap(destination_geo)[0]\n",
    "\n",
    "    # Get the lats and lons of the assocaited corners\n",
    "    overlap_lon = [i[0] for i in overlap_hull]\n",
    "    overlap_lat = [i[1] for i in overlap_hull]\n",
    "\n",
    "    # Define a ratio so the distrabution is even\n",
    "    overlap_ratio = (max(overlap_lon) - min(overlap_lon)) / (max(overlap_lat) - min(overlap_lat))\n",
    "\n",
    "    lon = np.linspace(min(overlap_lon) + .001, max(overlap_lon) - .001, size)\n",
    "    lat = np.linspace(min(overlap_lat) + .001, max(overlap_lat) - .001, round(size/overlap_ratio))\n",
    "    print('Generateing', len(lon), 'by', len(lat), 'point grid.')\n",
    "\n",
    "    # Get the lat, lon position for the grid\n",
    "    lonv, latv = np.meshgrid(lon, lat, sparse=True)\n",
    "\n",
    "    coords = []\n",
    "\n",
    "    # Begin looping over each point in the grid\n",
    "    for lat_val in latv:\n",
    "        for lon_val in lonv[0]:\n",
    "            # Find the point in pixel space for each image and get the value\n",
    "            x1, y1  = source_geo.latlon_to_pixel(lat_val[0], lon_val)\n",
    "            x2, y2  = destination_geo.latlon_to_pixel(lat_val[0], lon_val)\n",
    "            point_val1 = source_raster[y1 - 1, x1 - 1]\n",
    "            point_val2 = destination_raster[y2 - 1, x2 - 1]\n",
    "\n",
    "            # If either is zero then the point should be ignored\n",
    "            # as it lies outside of the true overlap\n",
    "            if point_val1 > 0 and point_val2 > 0:\n",
    "                coords.append([x1, y1, x2, y2, lat_val[0], lon_val])\n",
    "\n",
    "    # Build dataframe after grid contruction for data storage and \n",
    "    # ease of access\n",
    "    df = pd.DataFrame(coords, columns = ['source_x', \n",
    "                                         'source_y', \n",
    "                                         'destination_x', \n",
    "                                         'destination_y', \n",
    "                                         'lat', \n",
    "                                         'lon'])\n",
    "    return df\n",
    "\n",
    "# The Meat and Potatoes of offset calculation\n",
    "def compute_offsets(df, source_geo, destination_geo, template_size, search_size, corr_threshold=0.9):\n",
    "    # Define a template size and a search space size\n",
    "    s_img = source_geo\n",
    "\n",
    "    d_img = destination_geo\n",
    "\n",
    "    offsets = []\n",
    "    bound_mask = []\n",
    "\n",
    "    # Iterate through each point in the dataframe and calculate offsets\n",
    "    print('Computing Offsets')\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        x, y = row['source_x'], row['source_y']\n",
    "        s_template = sp.clip_roi(s_img, (x, y), template_size)\n",
    "\n",
    "\n",
    "        x, y = row['destination_x'], row['destination_y']\n",
    "        d_search = sp.clip_roi(d_img, (x, y), search_size)\n",
    "        \n",
    "        if not np.all(d_search) or not np.all(s_template):\n",
    "            bound_mask.append(False)\n",
    "        else:\n",
    "            bound_mask.append(True)\n",
    "\n",
    "        xoff, yoff, corr = sp.subpixel_offset(s_template, d_search)\n",
    "        xoff, yoff, corr = xoff, yoff,corr\n",
    "        # Apply the offsets to the source points and \n",
    "        # save those as well\n",
    "        offset_source_x = row['source_x'] - xoff\n",
    "        offset_source_y = row['source_y'] + yoff\n",
    "        offsets.append([offset_source_x, offset_source_y, xoff, yoff, corr])\n",
    "        sys.stdout.write('%s%s\\r' % (round((idx/len(df) * 100)), '% complete'))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    off_df = pd.DataFrame(offsets, columns = ['offset_source_x', 'offset_source_y', 'xoff', 'yoff', 'corr'])\n",
    "    comp_df = df.merge(off_df, left_index=True, right_index=True)[bound_mask]\n",
    "    \n",
    "    H, mask = compute_homography(comp_df.query('corr > {}'.format(corr_threshold)))\n",
    "    return comp_df, H, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_geo1 = GeoDataset(tiff_image1)\n",
    "tiff_geo2 = GeoDataset(tiff_image2)\n",
    "\n",
    "# Setup and redefine all 0 values as NaNs\n",
    "arr_image1 = tiff_geo1.read_array(1)\n",
    "arr_image1[arr_image1 == 0] = np.NaN\n",
    "\n",
    "arr_image2 = tiff_geo2.read_array(1)\n",
    "arr_image2[arr_image2 == 0] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(arr_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_x = [i[1] for i in overlap]\n",
    "overlap_y = [i[0] for i in overlap]\n",
    "\n",
    "# x1 = [i[1] for i in tiff_geo1.latlon_corners]\n",
    "# y1 = [i[0] for i in tiff_geo1.latlon_corners]\n",
    "\n",
    "# x2 = [i[1] for i in tiff_geo2.latlon_corners]\n",
    "# y2 = [i[0] for i in tiff_geo2.latlon_corners]\n",
    "\n",
    "plt.figure(0, figsize=(10, 10))\n",
    "# plt.imshow(arr_image1, extent = [min(y1), max(y1), min(x1), max(x1)], alpha = .5)\n",
    "# plt.imshow(arr_image2, extent = [min(y2), max(y2), min(x2), max(x2)], alpha = .5)\n",
    "plt.imshow(arr_image1, alpha = .5, cmap='plasma')\n",
    "plt.imshow(arr_image2, alpha = .5, cmap='plasma')\n",
    "# plt.scatter(overlap_y, overlap_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_initial_coregistration(arr_image1, arr_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate a dataframe of points associated with a grid where each point\n",
    "# in the grid is seperated by \n",
    "df = generate_point_grid(tiff_geo1, tiff_geo2, arr_image1, arr_image2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp_df, H, mask = compute_offsets(df, tiff_geo1, tiff_geo2, 25, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df[['xoff', 'yoff']].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df[['xoff', 'yoff']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.round(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add units\n",
    "comp_df[['xoff', 'yoff', 'corr']].describe([.25, .5, .75, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add descriptions/units\n",
    "plt.figure(0, figsize=(10, 10))\n",
    "comp_df[['xoff', 'yoff']].plot(kind='box', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10, 10))\n",
    "comp_df['corr'].plot(kind='box', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_quiver(comp_df, arr_image2, scale = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "examine_point(13, 201, comp_df, arr_image1, arr_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_homography(comp_df[mask], arr_image1, arr_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
