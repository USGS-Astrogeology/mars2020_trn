{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notes\n",
    "\n",
    "# Environment.yml for deploy\n",
    "# Create tiffs from cubes and clip to overlap using the warp/translate\n",
    "# Plot axes/label axes\n",
    "# Function documentation\n",
    "# Bin script tiff creation\n",
    "# Analysis bin script\n",
    "    # - Quiver png\n",
    "    # - Homography.txt (9 numbers)\n",
    "    # - Dataframe to csv (keep names the same)\n",
    "    # - Stats to csv (Dataframe describe data + quantile data(x, y, magnitude))\n",
    "\n",
    "# Box to Histogram\n",
    "# Correlation/Coregistration in Z dimension\n",
    "    # - Apply homography\n",
    "    # - Difference the two DTMs for some Z offset\n",
    "\n",
    "#-------Nice To Have-------\n",
    "# Specify meters or pixels for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Be sure to switch the kernel to autocnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import gdal\n",
    "import math\n",
    "import affine\n",
    "from osgeo import ogr\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, '/home/acpaquette/repos/plio')\n",
    "\n",
    "from plio.geofuncs import geofuncs\n",
    "from plio.io.io_gdal import GeoDataset\n",
    "from autocnet.matcher import subpixel as sp\n",
    "from autocnet.transformation import homography as hg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'plasma'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths and Files\n",
    "\n",
    "Similarly to the Image Conversion notebook this notebook requires a similar image setup. For now, I would copy the contents of that cell of the image conversion notebook into the cell bellow.\n",
    "Each cube requires a \"basepath\" and the cubes name.\n",
    "\n",
    "The basepath is the path to the directory containing the cubes. Ideally, you would want to place mutiple cubes within the same directory\n",
    "to make opening and accessing them easier. In the cell bellow, define various basepaths and cub names.\n",
    "\n",
    "You then can define the two cubes however you want using the basepath and a cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the paths to cubes and tiffs\n",
    "hirise_cub1 = \"ESP_023524_1985_1m_o_isis3.cub\"\n",
    "hirise_cub2 = \"ESP_048908_1985_1m_o_isis3.cub\"\n",
    "ctx_cub1 = \"F05_037607_2008_XN_20N282W_v6_PosAndVelAndAngles_20m_o.cub\"\n",
    "ctx_cub2 = \"J03_045994_1986_XN_18N282W_v6_20m_o.cub\"\n",
    "ctx_cub3 = \"F05_037607_2008_XN_20N282W_v6_PosAndVelAndAngles_6m_o.cub\"\n",
    "ctx_cub4 = \"J03_045994_1986_XN_18N282W_v6_6m_o.cub\"\n",
    "hrsc_cub = \"H5270_0000_ND4.IMG\"\n",
    "\n",
    "hirise_basepath = '/home/acpaquette/repos/mars2020_trn/TestData/HiRISE_Jezero/'\n",
    "ctx_20_basepath = '/home/acpaquette/repos/mars2020_trn/TestData/CTX_Jezero/20m_ctx/'\n",
    "ctx_6_basepath = '/home/acpaquette/repos/mars2020_trn/TestData/CTX_Jezero/6m_ctx/'\n",
    "hrsc_basepath = '/home/acpaquette/repos/mars2020_trn/TestData/HRSC_Jezero/'\n",
    "\n",
    "cub_image1 = os.path.join(hirise_basepath, hirise_cub1)\n",
    "cub_image2 = os.path.join(ctx_6_basepath, ctx_cub3)\n",
    "\n",
    "# cub_image1 = os.path.join(hrsc_basepath, hrsc_cub)\n",
    "# cub_image2 = os.path.join(ctx_20_basepath, ctx_cub1)\n",
    "\n",
    "# cub_image1 = os.path.join(ctx_20_basepath, ctx_cub1)\n",
    "# cub_image2 = os.path.join(ctx_20_basepath, ctx_cub2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "You can also define\n",
    "\n",
    "* Search Size \n",
    "    * Some integer i to generate and i x i search space\n",
    "    * Increasing this value will make the overall process take longer but be more precise\n",
    "* Template \n",
    "    * Size Some integer i to generate and i x i template\n",
    "    * Increasing this value will make the overall process shorter but less precise\n",
    "* Grid Size \n",
    "    * Some integer i to generate an i by j grid of points, where j is determined dynamically\n",
    "    * Increasing this value will make the overall process longer as there will be more points on the image\n",
    "* Correlation Threshold \n",
    "    * Some float <= 1 for how corrlated two points need to be to include in homography calculation\n",
    "    * Increasing this value will limit the system to points that are within the given percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_size = 101\n",
    "template_size = 25\n",
    "grid_size = 20\n",
    "corr_threshold = .7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the rest of it\n",
    "\n",
    "Once you have defined the cubes you want and the variables run the rest of the cells and wait for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the images and there overlapping grid area\n",
    "def show_initial_coregistration(source_image, destination_image):\n",
    "    plt.figure(0, figsize=(10, 10))\n",
    "    plt.imshow(source_image, alpha=.5, cmap='Greys')\n",
    "    plt.imshow(destination_image, alpha=.5, cmap='Greys')\n",
    "    plt.show()\n",
    "\n",
    "# Show the quiver plot of the offsets\n",
    "def display_quiver(comp_df, source_image, mask = [], scale = 100, scale_units = 'inches', **kwargs):\n",
    "    if len(mask) != 0:\n",
    "        comp_df = comp_df[mask]\n",
    "    \n",
    "    plt.figure(4, figsize=(20, 20))\n",
    "    plt.imshow(source_image, cmap=\"Greys\")\n",
    "    plt.quiver(comp_df['destination_x'], comp_df['destination_y'], \n",
    "               -(comp_df['xoff']), (comp_df['yoff']),\n",
    "               color = 'Red', scale = scale, scale_units = scale_units, **kwargs)\n",
    "    plt.show()\n",
    "    \n",
    "# Given an index in the dataframe examine the before and after\n",
    "# when the offset is applied\n",
    "def examine_point(idx, size, comp_df, source_image, destination_image, mask = []):\n",
    "    if len(mask) != 0:\n",
    "        comp_df = comp_df[mask]\n",
    "        \n",
    "    plt.figure(2, figsize=(5, 5))\n",
    "    plt.text(20, 50, 'Before Offset Correction', fontsize=12)\n",
    "    x, y = int(comp_df.iloc[idx]['source_x']), int(comp_df.iloc[idx]['source_y'])\n",
    "    plt.imshow(source_image[y - size:y + size, x - size:x + size], alpha = .5, cmap='Greys')\n",
    "\n",
    "    x, y = int(comp_df.iloc[idx]['destination_x']), int(comp_df.iloc[idx]['destination_y'])\n",
    "    plt.imshow(destination_image[y - size:y + size, x - size:x + size], alpha = .5, cmap='Greys')\n",
    "\n",
    "    plt.figure(3, figsize=(5, 5))\n",
    "    plt.text(20, 50, 'After Offset Correction', fontsize=12)\n",
    "    x, y = int(comp_df.iloc[idx]['offset_source_x']), int(comp_df.iloc[idx]['offset_source_y'])\n",
    "    plt.imshow(source_image[y - size: y + size, x - size: x + size], alpha = .5, cmap='Greys')\n",
    "\n",
    "    x, y = int(comp_df.iloc[idx]['destination_x']), int(comp_df.iloc[idx]['destination_y'])\n",
    "    plt.imshow(destination_image[y - size:y + size, x - size:x + size], alpha = .5, cmap='Greys')\n",
    "    plt.show()\n",
    "    \n",
    "    offset_x, offset_y, corr = comp_df.iloc[idx][['xoff', 'yoff', 'corr']]\n",
    "    print('X Offset: {}\\nY Offset: {}\\nCorrelation: {}'.format(offset_x, offset_y, corr))\n",
    "    \n",
    "def compute_homography(comp_df):\n",
    "    x1 = np.array([*zip(comp_df['offset_source_x'].__array__(), comp_df['offset_source_y'].__array__())])\n",
    "    x2 = np.array([*zip(comp_df['destination_x'].__array__(), comp_df['destination_y'].__array__())])\n",
    "    H, mask = hg.compute_homography(x1, x2)\n",
    "    \n",
    "    return H, mask\n",
    "\n",
    "# Apply the homography to the source image and display\n",
    "def apply_homography(comp_df, source_image, destination_image, H):\n",
    "    w, h = source_image.shape\n",
    "    result = cv2.warpPerspective(source_image, H, (h, w))\n",
    "    result[result == 0] = np.NAN\n",
    "\n",
    "    plt.figure(0, figsize=(30, 30))\n",
    "    plt.imshow(result, cmap='Greys', alpha = .5)\n",
    "    plt.imshow(destination_image, cmap='Greys', alpha = .5)\n",
    "    \n",
    "def generate_point_grid(source_geo, destination_geo, source_raster, destination_raster, size):\n",
    "    # Compute the overlap and get the corners now that\n",
    "    # we have the geometry\n",
    "    overlap_hull = source_geo.compute_overlap(destination_geo)[0]\n",
    "\n",
    "    # Get the lats and lons of the assocaited corners\n",
    "    overlap_lon = [i[0] for i in overlap_hull]\n",
    "    overlap_lat = [i[1] for i in overlap_hull]\n",
    "\n",
    "    # Define a ratio so the distrabution is even\n",
    "    overlap_ratio = (max(overlap_lon) - min(overlap_lon)) / (max(overlap_lat) - min(overlap_lat))\n",
    "\n",
    "    lon = np.linspace(min(overlap_lon) + .001, max(overlap_lon) - .001, size)\n",
    "    lat = np.linspace(min(overlap_lat) + .001, max(overlap_lat) - .001, round(size/overlap_ratio))\n",
    "\n",
    "    # Get the lat, lon position for the grid\n",
    "    lonv, latv = np.meshgrid(lon, lat, sparse=True)\n",
    "    print('Generating a', len(lonv[0]), 'by', len(latv), 'point grid')\n",
    "\n",
    "    coords = []\n",
    "\n",
    "    # Begin looping over each point in the grid\n",
    "    for lat_val in latv:\n",
    "        for lon_val in lonv[0]:\n",
    "            # Find the point in pixel space for each image and get the value\n",
    "            x1, y1  = source_geo.latlon_to_pixel(lat_val[0], lon_val)\n",
    "            x2, y2  = destination_geo.latlon_to_pixel(lat_val[0], lon_val)\n",
    "            point_val1 = source_raster[y1 - 1, x1 - 1]\n",
    "            point_val2 = destination_raster[y2 - 1, x2 - 1]\n",
    "\n",
    "            # If either is zero then the point should be ignored\n",
    "            # as it lies outside of the true overlap\n",
    "            if point_val1 > 0 and point_val2 > 0:\n",
    "                coords.append([x1, y1, x2, y2, lat_val[0], lon_val])\n",
    "\n",
    "    # Build dataframe after grid contruction for data storage and \n",
    "    # ease of access\n",
    "    df = pd.DataFrame(coords, columns = ['source_x', \n",
    "                                         'source_y', \n",
    "                                         'destination_x', \n",
    "                                         'destination_y', \n",
    "                                         'lat', \n",
    "                                         'lon'])\n",
    "    return df\n",
    "\n",
    "# The Meat and Potatoes of offset calculation\n",
    "def compute_offsets(df, s_img, d_img, template_size, search_size, corr_threshold=0.9):\n",
    "    offsets = []\n",
    "\n",
    "    # Iterate through each point in the dataframe and calculate offsets\n",
    "    print('Computing Offsets')\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        x, y = row['source_x'], row['source_y']\n",
    "        s_template = sp.clip_roi(s_img, (x, y), template_size)\n",
    "\n",
    "\n",
    "        x, y = row['destination_x'], row['destination_y']\n",
    "        d_search = sp.clip_roi(d_img, (x, y), search_size)\n",
    "\n",
    "        xoff, yoff, corr = sp.subpixel_offset(s_template, d_search)\n",
    "        mag = np.linalg.norm([xoff, yoff])\n",
    "        # Apply the offsets to the source points and \n",
    "        # save those as well\n",
    "        offset_source_x = row['source_x'] - xoff\n",
    "        offset_source_y = row['source_y'] + yoff\n",
    "        offsets.append([offset_source_x, offset_source_y, xoff, yoff, mag, corr])\n",
    "        sys.stdout.write('%s%s\\r' % (round((idx/len(df) * 100)), '% complete'))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    off_df = pd.DataFrame(offsets, columns = ['offset_source_x', 'offset_source_y', 'xoff', 'yoff', 'mag', 'corr'])\n",
    "    comp_df = df.merge(off_df, left_index=True, right_index=True)\n",
    "    corr_mask = comp_df['corr'] > corr_threshold\n",
    "    \n",
    "    H, mask = compute_homography(comp_df[corr_mask])\n",
    "    mask_index = comp_df[corr_mask][mask].index.__array__()\n",
    "    full_mask = [True if i in mask_index else False for i, val in comp_df.iterrows()]\n",
    "    return comp_df, H, full_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_image1 = os.path.splitext(cub_image1)[0] + '.tiff'\n",
    "tiff_image2 = os.path.splitext(cub_image2)[0] + '.tiff'\n",
    "\n",
    "tiff_geo1 = GeoDataset(tiff_image1)\n",
    "tiff_geo2 = GeoDataset(tiff_image2)\n",
    "\n",
    "# Setup and redefine all 0 values as NaNs\n",
    "arr_image1 = tiff_geo1.read_array(1)\n",
    "arr_image1[arr_image1 == 0] = np.NaN\n",
    "\n",
    "arr_image2 = tiff_geo2.read_array(1)\n",
    "arr_image2[arr_image2 == 0] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_initial_coregistration(arr_image1, arr_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate a dataframe of points associated with a grid where each point\n",
    "# in the grid is seperated by\n",
    "df = generate_point_grid(tiff_geo1, tiff_geo2, arr_image1, arr_image2, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp_df, H, mask = compute_offsets(df, tiff_geo1, tiff_geo2, template_size, search_size, corr_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Data\n",
    "\n",
    "The three cells bellow are all focused on the statistics of the computation.\n",
    "\n",
    "## Units\n",
    "\n",
    "__Xoff__: All pixel values, displaying stats on the shift in the x direction <br>\n",
    "__Yoff__: All pixel values, displaying stats on the shift in the y direction <br>\n",
    "__Corr__: All as percentages, displaying stats on the correlation between point comparisons in the current calculation\n",
    "\n",
    "This goes for both the table bellow and the three box plots bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add units\n",
    "comp_df[mask][['xoff', 'yoff', 'corr']].describe([.25, .5, .75, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add descriptions/units\n",
    "plot = comp_df[mask][['xoff', 'yoff']].plot(kind='box', figsize=(10, 10))\n",
    "plot.set_ylabel('Pixel Offset', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = comp_df['corr'][mask].plot(kind='box', figsize=(10, 10))\n",
    "plot.set_ylabel('Percentage', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiver Plot Display\n",
    "\n",
    "Uses the comp_df's x, and y offsets to generate the quiver arrows. While they seem exaggerated they size of a quiver is relative to it's magnitude. Where scale uses the magnitude to draw itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_quiver(comp_df[mask], arr_image2, scale = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Point Display\n",
    "\n",
    "The first value is the point on the image from left to right, bottom to top.<br>That is, the leftmost, bottom point is 0, the next to the right is 1, etc.\n",
    "\n",
    "The second value is the size of the area to display in pixels as a square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "examine_point(0, 100, comp_df[mask], arr_image1, arr_image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homography Application\n",
    "\n",
    "Uses the homography generated by the initial compute offsets function to realign the initial images.\n",
    "<br>This is only as accurate as the homography that was generated and is more or less a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_homography(comp_df[mask], arr_image1, arr_image2, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "autocnet",
   "language": "python",
   "name": "autocnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
