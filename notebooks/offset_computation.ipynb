{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notes\n",
    "\n",
    "# Environment.yml for deploy\n",
    "# Create tiffs from cubes and clip to overlap using the warp/translate\n",
    "# Plot axes/label axes\n",
    "# Function documentation\n",
    "# Bin script tiff creation\n",
    "# Analysis bin script\n",
    "    # - Quiver png\n",
    "    # - Homography.txt (9 numbers)\n",
    "    # - Dataframe to csv (keep names the same)\n",
    "    # - Stats to csv (Dataframe describe data + quantile data(x, y, magnitude))\n",
    "\n",
    "# Box to Histogram\n",
    "# Correlation/Coregistration in Z dimension\n",
    "    # - Apply homography\n",
    "    # - Difference the two DTMs for some Z offset\n",
    "\n",
    "#-------Nice To Have-------\n",
    "# Specify meters or pixels for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import gdal\n",
    "import math\n",
    "import affine\n",
    "from osgeo import ogr\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, '/home/acpaquette/repos/plio')\n",
    "\n",
    "from plio.geofuncs import geofuncs\n",
    "from plio.io.io_gdal import GeoDataset\n",
    "from autocnet.matcher import subpixel as sp\n",
    "from autocnet.transformation import homography as hg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'plasma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup the paths to cubes and tiffs\n",
    "hirise_cub1 = \"ESP_023524_1985_1m_o_isis3.cub\"\n",
    "hirise_cub2 = \"ESP_048908_1985_1m_o_isis3.cub\"\n",
    "ctx_cub1 = \"F05_037607_2008_XN_20N282W_v6_PosAndVelAndAngles_20m_o.cub\"\n",
    "ctx_cub2 = \"J03_045994_1986_XN_18N282W_v6_20m_o.cub\"\n",
    "ctx_cub3 = \"F05_037607_2008_XN_20N282W_v6_PosAndVelAndAngles_6m_o.cub\"\n",
    "ctx_cub4 = \"J03_045994_1986_XN_18N282W_v6_6m_o.cub\"\n",
    "hrsc_cub = \"H5270_0000_ND4.IMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basepath = '/home/acpaquette/repos/mars2020_trn/TestData/HiRISE_Jezero/'\n",
    "# basepath = '/home/acpaquette/repos/mars2020_trn/TestData/CTX_Jezero/20m_ctx/'\n",
    "basepath = '/home/acpaquette/repos/mars2020_trn/TestData/CTX_Jezero/6m_ctx/'\n",
    "# basepath = '/home/acpaquette/repos/mars2020_trn/TestData/HRSC_Jezero/'\n",
    "\n",
    "cub_image1 = os.path.join('/home/acpaquette/repos/mars2020_trn/TestData/HiRISE_Jezero/', hirise_cub1)\n",
    "cub_image2 = os.path.join(basepath, ctx_cub4)\n",
    "\n",
    "tiff_image1 = os.path.splitext(cub_image1)[0] + '.tiff'\n",
    "tiff_image2 = os.path.splitext(cub_image2)[0] + '.tiff'\n",
    "\n",
    "src_in_srs = gdal.Info(cub_image1, format='json')['coordinateSystem']['wkt']\n",
    "dst_in_srs = gdal.Info(cub_image2, format='json')['coordinateSystem']['wkt']\n",
    "\n",
    "if 'Equirectangular' in src_in_srs:\n",
    "    out_srs = src_in_srs\n",
    "elif 'Equirectangular' in dst_in_srs:\n",
    "    out_srs = dst_in_srs\n",
    "\n",
    "resample = 'bilinear'\n",
    "res = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all geo data for the two co-registered tiffs\n",
    "cub_geo1 = GeoDataset(cub_image1)\n",
    "cub_geo2 = GeoDataset(cub_image2)\n",
    "\n",
    "overlap = cub_geo1.compute_overlap(cub_geo2)[0]\n",
    "\n",
    "overlap_points1 = [cub_geo1.latlon_to_pixel(i[1], i[0]) for i in overlap][::2]\n",
    "overlap_points2 = [cub_geo2.latlon_to_pixel(i[1], i[0]) for i in overlap][::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(tiff_image_mod1):\n",
    "ul, lr = overlap_points1\n",
    "\n",
    "minx1, miny1= ul\n",
    "maxx1, maxy1 = lr\n",
    "\n",
    "fp = gdal.Translate(tiff_image1, cub_image1, srcWin = [minx1, miny1, maxx1 - minx1, maxy1 - miny1])\n",
    "del(fp)\n",
    "\n",
    "fp = gdal.Warp(tiff_image1, tiff_image1, \n",
    "               targetAlignedPixels=True, \n",
    "               xRes = res, yRes = res, \n",
    "               resampleAlg=resample,\n",
    "               srcSRS=src_in_srs,\n",
    "               dstSRS=out_srs)\n",
    "del(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(tiff_image_mod2):\n",
    "ul, lr = overlap_points2\n",
    "\n",
    "minx2, miny2= ul\n",
    "maxx2, maxy2 = lr\n",
    "\n",
    "fp = gdal.Translate(tiff_image2, cub_image2, srcWin = [minx2, miny2, maxx2 - minx2, maxy2 - miny2])\n",
    "del(fp)\n",
    "\n",
    "fp = gdal.Warp(tiff_image2, tiff_image2,\n",
    "               targetAlignedPixels=True, \n",
    "               xRes = res, yRes = res, \n",
    "               resampleAlg=resample, \n",
    "               srcSRS=dst_in_srs, \n",
    "               dstSRS=out_srs)\n",
    "del(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the images and there overlapping grid area\n",
    "def show_initial_coregistration(source_image, destination_image):\n",
    "    plt.figure(0, figsize=(10, 10))\n",
    "    plt.imshow(source_image, alpha=.5, cmap='Greys')\n",
    "    plt.imshow(destination_image, alpha=.5, cmap='Greys')\n",
    "    plt.show()\n",
    "\n",
    "# Show the quiver plot of the offsets\n",
    "def display_quiver(comp_df, source_image, mask = [], scale = 100, scale_units = 'inches', **kwargs):\n",
    "    if len(mask) != 0:\n",
    "        comp_df = comp_df[mask]\n",
    "    \n",
    "    plt.figure(4, figsize=(20, 20))\n",
    "    plt.imshow(source_image, cmap=\"Greys\")\n",
    "    plt.quiver(comp_df['destination_x'], comp_df['destination_y'], \n",
    "               -(comp_df['xoff']), (comp_df['yoff']),\n",
    "               color = 'Red', scale = scale, scale_units = scale_units, **kwargs)\n",
    "    plt.show()\n",
    "    \n",
    "# Given an index in the dataframe examine the before and after\n",
    "# when the offset is applied\n",
    "def examine_point(idx, size, comp_df, source_image, destination_image, mask = []):\n",
    "    if len(mask) != 0:\n",
    "        comp_df = comp_df[mask]\n",
    "        \n",
    "    plt.figure(2, figsize=(5, 5))\n",
    "    plt.text(20, 50, 'Before Offset Correction', fontsize=12)\n",
    "    x, y = int(comp_df.iloc[idx]['source_x']), int(comp_df.iloc[idx]['source_y'])\n",
    "    plt.imshow(source_image[y - size:y + size, x - size:x + size], alpha = .5, cmap='Greys')\n",
    "\n",
    "    x, y = int(comp_df.iloc[idx]['destination_x']), int(comp_df.iloc[idx]['destination_y'])\n",
    "    plt.imshow(destination_image[y - size:y + size, x - size:x + size], alpha = .5, cmap='Greys')\n",
    "\n",
    "    plt.figure(3, figsize=(5, 5))\n",
    "    plt.text(20, 50, 'After Offset Correction', fontsize=12)\n",
    "    x, y = int(comp_df.iloc[idx]['offset_source_x']), int(comp_df.iloc[idx]['offset_source_y'])\n",
    "    plt.imshow(source_image[y - size: y + size, x - size: x + size], alpha = .5, cmap='Greys')\n",
    "\n",
    "    x, y = int(comp_df.iloc[idx]['destination_x']), int(comp_df.iloc[idx]['destination_y'])\n",
    "    plt.imshow(destination_image[y - size:y + size, x - size:x + size], alpha = .5, cmap='Greys')\n",
    "    plt.show()\n",
    "    \n",
    "    offset_x, offset_y, corr = comp_df.iloc[idx][['xoff', 'yoff', 'corr']]\n",
    "    print('X Offset: {}\\nY Offset: {}\\nCorrelation: {}'.format(offset_x, offset_y, corr))\n",
    "    \n",
    "def compute_homography(comp_df):\n",
    "    x1 = np.array([*zip(comp_df['offset_source_x'].__array__(), comp_df['offset_source_y'].__array__())])\n",
    "    x2 = np.array([*zip(comp_df['destination_x'].__array__(), comp_df['destination_y'].__array__())])\n",
    "    H, mask = hg.compute_homography(x1, x2)\n",
    "    \n",
    "    return H, mask\n",
    "\n",
    "# Apply the homography to the source image and display\n",
    "def apply_homography(comp_df, source_image, destination_image):\n",
    "    H, mask = compute_homography(comp_df)\n",
    "\n",
    "    w, h = source_image.shape\n",
    "    result = cv2.warpPerspective(source_image, H, (h, w))\n",
    "    result[result == 0] = np.NAN\n",
    "\n",
    "    plt.figure(0, figsize=(30, 30))\n",
    "    plt.imshow(result, cmap='Greys', alpha = .5)\n",
    "    plt.imshow(destination_image, cmap='Greys', alpha = .5)\n",
    "    \n",
    "def generate_point_grid(source_geo, destination_geo, source_raster, destination_raster, size):\n",
    "    # Compute the overlap and get the corners now that\n",
    "    # we have the geometry\n",
    "    overlap_hull = source_geo.compute_overlap(destination_geo)[0]\n",
    "\n",
    "    # Get the lats and lons of the assocaited corners\n",
    "    overlap_lon = [i[0] for i in overlap_hull]\n",
    "    overlap_lat = [i[1] for i in overlap_hull]\n",
    "\n",
    "    # Define a ratio so the distrabution is even\n",
    "    overlap_ratio = (max(overlap_lon) - min(overlap_lon)) / (max(overlap_lat) - min(overlap_lat))\n",
    "\n",
    "    lon = np.linspace(min(overlap_lon) + .001, max(overlap_lon) - .001, size)\n",
    "    lat = np.linspace(min(overlap_lat) + .001, max(overlap_lat) - .001, round(size/overlap_ratio))\n",
    "    print('Generateing', len(lon), 'by', len(lat), 'point grid.')\n",
    "\n",
    "    # Get the lat, lon position for the grid\n",
    "    lonv, latv = np.meshgrid(lon, lat, sparse=True)\n",
    "\n",
    "    coords = []\n",
    "\n",
    "    # Begin looping over each point in the grid\n",
    "    for lat_val in latv:\n",
    "        for lon_val in lonv[0]:\n",
    "            # Find the point in pixel space for each image and get the value\n",
    "            x1, y1  = source_geo.latlon_to_pixel(lat_val[0], lon_val)\n",
    "            x2, y2  = destination_geo.latlon_to_pixel(lat_val[0], lon_val)\n",
    "            point_val1 = source_raster[y1 - 1, x1 - 1]\n",
    "            point_val2 = destination_raster[y2 - 1, x2 - 1]\n",
    "\n",
    "            # If either is zero then the point should be ignored\n",
    "            # as it lies outside of the true overlap\n",
    "            if point_val1 > 0 and point_val2 > 0:\n",
    "                coords.append([x1, y1, x2, y2, lat_val[0], lon_val])\n",
    "\n",
    "    # Build dataframe after grid contruction for data storage and \n",
    "    # ease of access\n",
    "    df = pd.DataFrame(coords, columns = ['source_x', \n",
    "                                         'source_y', \n",
    "                                         'destination_x', \n",
    "                                         'destination_y', \n",
    "                                         'lat', \n",
    "                                         'lon'])\n",
    "    return df\n",
    "\n",
    "# The Meat and Potatoes of offset calculation\n",
    "def compute_offsets(df, s_img, d_img, template_size, search_size, corr_threshold=0.9):\n",
    "    offsets = []\n",
    "\n",
    "    # Iterate through each point in the dataframe and calculate offsets\n",
    "    print('Computing Offsets')\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        x, y = row['source_x'], row['source_y']\n",
    "        s_template = sp.clip_roi(s_img, (x, y), template_size)\n",
    "\n",
    "\n",
    "        x, y = row['destination_x'], row['destination_y']\n",
    "        d_search = sp.clip_roi(d_img, (x, y), search_size)\n",
    "\n",
    "        xoff, yoff, corr = sp.subpixel_offset(s_template, d_search)\n",
    "        mag = np.linalg.norm([xoff, yoff])\n",
    "        # Apply the offsets to the source points and \n",
    "        # save those as well\n",
    "        offset_source_x = row['source_x'] - xoff\n",
    "        offset_source_y = row['source_y'] + yoff\n",
    "        offsets.append([offset_source_x, offset_source_y, xoff, yoff, mag, corr])\n",
    "        sys.stdout.write('%s%s\\r' % (round((idx/len(df) * 100)), '% complete'))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    off_df = pd.DataFrame(offsets, columns = ['offset_source_x', 'offset_source_y', 'xoff', 'yoff', 'mag', 'corr'])\n",
    "    comp_df = df.merge(off_df, left_index=True, right_index=True)\n",
    "    corr_mask = comp_df['corr'] > corr_threshold\n",
    "    \n",
    "    H, mask = compute_homography(comp_df[corr_mask])\n",
    "    mask_index = comp_df[corr_mask][mask].index.__array__()\n",
    "    full_mask = [True if i in mask_index else False for i, val in comp_df.iterrows()]\n",
    "    return comp_df, H, full_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tiff_geo1 = GeoDataset(tiff_image1)\n",
    "tiff_geo2 = GeoDataset(tiff_image2)\n",
    "\n",
    "# Setup and redefine all 0 values as NaNs\n",
    "arr_image1 = tiff_geo1.read_array(1)\n",
    "arr_image1[arr_image1 == 0] = np.NaN\n",
    "\n",
    "arr_image2 = tiff_geo2.read_array(1)\n",
    "arr_image2[arr_image2 == 0] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_initial_coregistration(arr_image1, arr_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate a dataframe of points associated with a grid where each point\n",
    "# in the grid is seperated by \n",
    "df = generate_point_grid(tiff_geo1, tiff_geo2, arr_image1, arr_image2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp_df, H, mask = compute_offsets(df, tiff_geo1, tiff_geo2, 25, 101, corr_threshold=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.round(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add units\n",
    "comp_df[mask][['xoff', 'yoff', 'corr']].describe([.25, .5, .75, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add descriptions/units\n",
    "plt.figure(0, figsize=(10, 10))\n",
    "comp_df[mask][['xoff', 'yoff']].plot(kind='box', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10, 10))\n",
    "comp_df['corr'][mask].plot(kind='box', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_quiver(comp_df[mask], arr_image2, scale = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "examine_point(10, 201, comp_df[mask], arr_image1, arr_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_homography(comp_df[mask], arr_image1, arr_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "autocnet",
   "language": "python",
   "name": "autocnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
