{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gdal\n",
    "from plio.io.io_gdal import GeoDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths, Files and Variables\n",
    "\n",
    "Each cube requires a \"basepath\" and the cubes name.\n",
    "\n",
    "The basepath is the path to the directory containing the cubes. Ideally, you would want to place mutiple cubes within the same directory\n",
    "to make opening and accessing them easier. In the cell bellow, define various basepaths and cub names.\n",
    "\n",
    "You then can define the two cubes however you want using the basepath and a cube.\n",
    "\n",
    "This also allows you to define the resampleing algorithm to use in the gdal warp and the resolution size of the tiff after the warp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hirise_basepath = '/home/acpaquette/repos/ortho_map_comparison_code/TestData/HiRISE_Jezero/'\n",
    "ctx_20_basepath = '/home/acpaquette/repos/ortho_map_comparison_code/TestData/CTX_Jezero/20m_ctx'\n",
    "ctx_6_basepath = '/home/acpaquette/repos/ortho_map_comparison_code/TestData/CTX_Jezero/6m_ctx'\n",
    "hrsc_basepath = '/home/acpaquette/repos/ortho_map_comparison_code/TestData/HRSC_Jezero/'\n",
    "\n",
    "hirise_dem1 = os.path.join(hirise_basepath, 'DEM_1m_Jezero_CE_isis3.cub')\n",
    "hirise_dem2 = os.path.join(hirise_basepath, 'DEM_1m_Jezero_C_isis3.cub')\n",
    "\n",
    "ctx_dem1 = os.path.join(ctx_6_basepath, 'tfm_abso_Jezero_F05_V6_IAUsph_adj_XYZposAndVelAndAngles_20m_onePassAfterngate.cub')\n",
    "ctx_dem2 = os.path.join(ctx_6_basepath, 'tfm_abso_Jezero_J03_V6_IAUsph_adj_XYZposAndVelAndAngles_20m_onePassAfterngate.cub')\n",
    "\n",
    "# setup the paths to cubes and tiffs\n",
    "hirise_cub1 = \"ESP_023524_1985_1m_o_isis3.cub\"\n",
    "hirise_cub2 = \"ESP_048908_1985_1m_o_isis3.cub\"\n",
    "ctx_cub1 = \"F05_037607_2008_XN_20N282W_v6_PosAndVelAndAngles_20m_o.cub\"\n",
    "ctx_cub2 = \"J03_045994_1986_XN_18N282W_v6_20m_o.cub\"\n",
    "ctx_cub3 = \"F05_037607_2008_XN_20N282W_v6_PosAndVelAndAngles_6m_o.cub\"\n",
    "ctx_cub4 = \"J03_045994_1986_XN_18N282W_v6_6m_o.cub\"\n",
    "hrsc_cub = \"H5270_0000_ND4.IMG\"\n",
    "\n",
    "# cub_image1 = os.path.join(hirise_basepath, hirise_cub1)\n",
    "# cub_image2 = os.path.join(hirise_basepath, hirise_cub2)\n",
    "\n",
    "# cub_image1 = os.path.join(ctx_6_basepath, ctx_cub3)\n",
    "# cub_image2 = os.path.join(ctx_6_basepath, ctx_cub4)\n",
    "\n",
    "cub_image1 = os.path.join(ctx_20_basepath, ctx_cub1)\n",
    "cub_image2 = os.path.join(ctx_20_basepath, ctx_cub2)\n",
    "\n",
    "# cub_image1 = hirise_dem1\n",
    "# cub_image2 = hirise_dem2\n",
    "\n",
    "# cub_image1 = ctx_dem1\n",
    "# cub_image2 = ctx_dem2\n",
    "\n",
    "# Resampling Algorithm\n",
    "resample_type = 'bilinear'\n",
    "\n",
    "# Resolution (x meters per pixel)\n",
    "res = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions for applying the image process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_worldfile(file):\n",
    "    \n",
    "    world_file = os.path.splitext(file)[0] + \".tfw\"\n",
    "    \n",
    "    with open(world_file, \"w\") as fp:\n",
    "        \n",
    "        cub_geo = GeoDataset(file)\n",
    "        geotransform = cub_geo.geotransform\n",
    "        \n",
    "        if geotransform is not None:\n",
    "            x, x_size, x_rot, y, y_rot, y_size = geotransform\n",
    "            fp.write('%s\\n' % x_size)\n",
    "            fp.write('%s\\n' % x_rot)\n",
    "            fp.write('%s\\n' % y_rot)\n",
    "            fp.write('%s\\n' % y_size)\n",
    "            fp.write('%s\\n' % x)\n",
    "            fp.write('%s\\n' % y)\n",
    "            fp.close()\n",
    "\n",
    "def translate_image(in_image, out_image, overlap_points, res, resample_type, in_srs, out_srs, out_type = \"GTiff\"):\n",
    "    ul, lr = overlap_points\n",
    "\n",
    "    minx, miny= ul\n",
    "    maxx, maxy = lr\n",
    "\n",
    "    fp = gdal.Translate(out_image, in_image, srcWin = [minx, miny, maxx - minx, maxy - miny])\n",
    "    del(fp)\n",
    "\n",
    "    fp = gdal.Warp(out_image, out_image, targetAlignedPixels=True, xRes = res, yRes = res, resampleAlg = resample_type, srcSRS = in_srs, dstSRS = out_srs, format = out_type)\n",
    "    del(fp)\n",
    "    \n",
    "def process_coreg_cubs(cub_image1, cub_image2, res, resample_type, out_type = 'GTiff', gen_worldfile = False):\n",
    "    \n",
    "    if gen_worldfile:\n",
    "        generate_worldfile(cub_image1)\n",
    "        generate_worldfile(cub_image2)\n",
    "    \n",
    "    tiff_image1 = os.path.splitext(cub_image1)[0]\n",
    "    tiff_image2 = os.path.splitext(cub_image2)[0]\n",
    "\n",
    "    src_in_srs = gdal.Info(cub_image1, format='json')['coordinateSystem']['wkt']\n",
    "    dst_in_srs = gdal.Info(cub_image2, format='json')['coordinateSystem']['wkt']\n",
    "\n",
    "    if 'Equirectangular' in src_in_srs:\n",
    "        src_out_srs = src_in_srs\n",
    "    else:\n",
    "        if 'Equirectangular' in dst_in_srs:\n",
    "            src_out_srs = dst_in_srs\n",
    "\n",
    "    if 'Equirectangular' in dst_in_srs:\n",
    "        dst_out_srs = dst_in_srs\n",
    "    else:\n",
    "        if 'Equirectangular' in src_in_srs:\n",
    "\n",
    "            dst_out_srs = src_in_srs\n",
    "            \n",
    "    # Get all geo data for the two co-registered tiffs\n",
    "    cub_geo1 = GeoDataset(cub_image1)\n",
    "    cub_geo2 = GeoDataset(cub_image2)\n",
    "\n",
    "    overlap = cub_geo1.compute_overlap(cub_geo2)[0]\n",
    "\n",
    "    overlap_points1 = [cub_geo1.latlon_to_pixel(i[1], i[0]) for i in overlap][::2]\n",
    "    overlap_points2 = [cub_geo2.latlon_to_pixel(i[1], i[0]) for i in overlap][::2]\n",
    "    \n",
    "    translate_image(cub_image1, tiff_image1, overlap_points1, res, resample_type, src_in_srs, src_out_srs, out_type=out_type)\n",
    "    translate_image(cub_image2, tiff_image2, overlap_points2, res, resample_type, dst_in_srs, dst_out_srs, out_type=out_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_coreg_cubs(cub_image1, cub_image2, res, resample_type, out_type='GTiff', gen_worldfile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
